{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "import concurrent\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_call(api_source, config, gpt_model, system_content, prompt, drug, adr, temperature):\n",
    "    if api_source == 'OpenAI':\n",
    "        client = OpenAI(api_key=config[api_source]['openai_api_key'])\n",
    "    elif api_source == 'Azure':\n",
    "        client = AzureOpenAI(api_key=config[api_source]['openai_api_key'], api_version=\"2023-12-01-preview\", azure_endpoint=config[api_source]['openai_api_endpoint'])\n",
    "    else:\n",
    "        raise Exception(f\"Unexpected API source requested: {api_source}\")\n",
    "  \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt.format(adr, drug)\n",
    "            }\n",
    "        ],\n",
    "        model=gpt_model,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    term = chat_completion.choices[0].message.content\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('./config.json'))\n",
    "\n",
    "organization = \"\"\n",
    "\n",
    "api_source = 'OpenAI'\n",
    "\n",
    "api_key = config[api_source]['openai_api_key'] #constants.AZURE_OPENAI_KEY\n",
    "api_endpoint = config[api_source]['openai_api_endpoint'] \n",
    "\n",
    "gpt_model = config[api_source][\"gpt_model\"]\n",
    "temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nruns = 3\n",
    "\n",
    "system_options = {\n",
    "    \"lie-detector\": \"\"\"\n",
    "    You are a lie detector. You will be given a statement and you have to determine if it is true or false.\n",
    "    Do not include an explanation. Only respond with \"true\" or \"false\".\n",
    "    \"\"\",\n",
    "    \"pharmaco-expert\": \"\"\"\n",
    "    You are a pharmacologist. You will be given a statement regarding a drug and potential adverse reaction\n",
    "    and you have to determine state whether it is true or false.\n",
    "    Do not include an explanation. Only respond with \"true\" or \"false\".\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "prompt_options = {\n",
    "    \"side-effect\": \"\"\"\n",
    "True or False: {} is a side effect caused by {}.\n",
    "\"\"\",\n",
    "    \"adverse-reaction\": \"\"\"\n",
    "{} is an adverse reaction of {}.\n",
    "\"\"\",\n",
    "    \"caused-by\": \"\"\"\n",
    "{} is caused by {}.\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_name = \"pharmaco-expert\"\n",
    "system_content = system_options[system_name]\n",
    "\n",
    "prompt_name = \"adverse-reaction\"\n",
    "prompt = prompt_options[prompt_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_section = pd.read_csv('/Users/undinagisladottir/Documents/Columbia/Tatonetti_Lab/20231113_onsides/adverse_reactions_active_labels.csv')\n",
    "adr_section.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_mapping = pd.read_csv('/Users/undinagisladottir/Documents/Columbia/Tatonetti_Lab/20231113_onsides/adverse_reactions_active_labels.csv')\n",
    "for_mapping.drop(for_mapping[for_mapping.ingredients_names.isna()].index, inplace=True)\n",
    "adr_section = pd.read_csv('/Users/undinagisladottir/Documents/Columbia/Tatonetti_Lab/20231113_onsides/adverse_reactions_active_labels.csv')\n",
    "print(adr_section.shape)\n",
    "adr_section.drop(adr_section[adr_section.ingredients_names.isna()].index, inplace=True)\n",
    "print(adr_section.shape)\n",
    "adr_section = adr_section[['pt_meddra_term', 'pt_meddra_id', 'set_id', 'ingredients_rxcuis', 'ingredients_names']].drop_duplicates()\n",
    "print(adr_section.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_run = adr_section.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(rows_to_run[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in rows_to_run:\n",
    "    drug = row[4]\n",
    "    adr = row[0]\n",
    "    pt_meddra_id = row[1]\n",
    "    spl_id = i[2]\n",
    "    rxcui = i[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iteration(row):\n",
    "    drug = row[4]\n",
    "    adr = row[0]\n",
    "    pt_meddra_id = row[1]\n",
    "    rxcui = i[3]\n",
    "     \n",
    "    try:\n",
    "        gpt_out = gpt_call(api_source, config, gpt_model, system_content, prompt, drug, adr, temperature)\n",
    "        return [drug, rxcui, adr, pt_meddra_id, gpt_out]\n",
    "    except Exception as err:\n",
    "        print(f\"Encountered an exception for row: {drug} {adr}. Error message below:\")\n",
    "        print(err)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):    \n",
    "    results = list()\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as exec:\n",
    "        results.extend(list(tqdm(\n",
    "            exec.map(run_iteration, rows_to_run), \n",
    "            total=len(rows_to_run)\n",
    "        )))\n",
    "            \n",
    "    gpt_output = pd.DataFrame(\n",
    "        [r for r in results if r is not None],\n",
    "        columns=['drug_name', 'spl_id', 'rxcui',  'adr_name', 'pt_meddra_id', 'gpt_output']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output['response'] = ['true' if 'true' in x.lower() else 'false' for x in gpt_output['gpt_output']]\n",
    "gpt_output.response.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{system_name}_{prompt_name}_run{i}.csv')\n",
    "for i in range(1):    \n",
    "    results = list()\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as exec:\n",
    "        results.extend(list(tqdm(\n",
    "            exec.map(run_iteration, rows_to_run), \n",
    "            total=len(rows_to_run)\n",
    "        )))\n",
    "            \n",
    "    gpt_output = pd.DataFrame(\n",
    "        [r for r in results if r is not None],\n",
    "        columns=['drug_name', 'adr_name', 'gpt_output']\n",
    "    )\n",
    "    gpt_output.to_csv(f'{system_name}_{prompt_name}_run{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output['response'] = ['true' if 'true' in x.lower() else 'false' for x in gpt_output['gpt_output']]\n",
    "gpt_output.drop(gpt_output[gpt_output.drug_name.isna()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output[gpt_output.gpt_output == 'False. (The statement is incomplete and \"nan\" is not a recognizable drug or substance.)'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output.response.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement with Reference Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output = pd.read_csv('lie-detector_side-effect_run0.csv')\n",
    "gpt_output['response'] = ['true' if 'true' in x.lower() else 'false' for x in gpt_output['gpt_output']]\n",
    "gpt_output.drop(gpt_output[gpt_output.drug_name.isna()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_set = pd.read_csv('reference_set_labels.csv')\n",
    "reference_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meddra_reference_map = pd.read_csv('/Users/undinagisladottir/Documents/Columbia/Tatonetti_Lab/causal-drug-ades/mapping_reference.csv')\n",
    "meddra_reference_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meddra_reference_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gpt_output.merge(meddra_reference_map, how='inner', left_on='adr_name', right_on='concept_name')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gpt_output.merge(\n",
    "    meddra_reference_map, how='inner', left_on='adr_name', right_on='concept_name'\n",
    "    ).merge(\n",
    "        reference_set, on=['drug_name', 'condition_name', 'cohort_id'], how='inner'\n",
    "        )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.groupby(['response', 'affect']).size().reset_index(name='n')\n",
    "data = data.merge(\n",
    "    data.groupby('affect').sum().reset_index()[['affect', 'n']].rename(columns={'n':'total'}),\n",
    "    on = 'affect'\n",
    ")\n",
    "data['perc'] = data['n'] / data['n'].groupby(data['affect']).transform('sum')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = data[['drug_name', 'condition_name', 'affect', 'response']]\n",
    "data.groupby(['drug_name', 'condition_name', 'affect']).agg(lambda response: any(response == 'true')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by drug_name and condition_name, get max(affect) and response = true if any are true\n",
    "data[['response', 'affect']].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.groupby(['response', 'affect']).size().reset_index(name='n')\n",
    "data = data.merge(\n",
    "    data.groupby('affect').sum().reset_index()[['affect', 'n']].rename(columns={'n':'total'}),\n",
    "    on = 'affect'\n",
    ")\n",
    "data['perc'] = data['n'] / data['n'].groupby(data['affect']).transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_set.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_run = reference_set[['condition_name', 'drug_name']].values.tolist()\n",
    "for i in range(1):    \n",
    "    results = list()\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as exec:\n",
    "        results.extend(list(tqdm(\n",
    "            exec.map(run_iteration, rows_to_run), \n",
    "            total=len(rows_to_run)\n",
    "        )))\n",
    "            \n",
    "    gpt_output = pd.DataFrame(\n",
    "        [r for r in results if r is not None],\n",
    "        columns=['drug_name', 'adr_name', 'gpt_output']\n",
    "    )\n",
    "    gpt_output.to_csv(f'{system_name}_{prompt_name}_referenceset_run{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{system_name}_{prompt_name}_referenceset_run{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_res = reference_set.merge(\n",
    "    gpt_output,\n",
    "      right_on=['drug_name', 'adr_name'],\n",
    "      left_on=['drug_name', 'condition_name'],\n",
    "      how='inner'\n",
    ")\n",
    "ref_res['response'] = ['true' if 'true' in x.lower() else 'false' for x in ref_res['gpt_output']]\n",
    "print(ref_res[['affect', 'response']].value_counts())\n",
    "ref_res = ref_res.groupby(['response', 'affect']).size().reset_index(name='n')\n",
    "ref_res = ref_res.merge(\n",
    "    ref_res.groupby('affect').sum().reset_index()[['affect', 'n']].rename(columns={'n':'total'}),\n",
    "    on = 'affect'\n",
    ")\n",
    "ref_res['perc'] = ref_res['n'] / ref_res['n'].groupby(ref_res['affect']).transform('sum')\n",
    "print(ref_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_res.sort_values(by=['affect', 'response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining with Reference Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_call(api_source, config, gpt_model, system_content, prompt, drug, adr, temperature):\n",
    "    if api_source == 'OpenAI':\n",
    "        client = OpenAI(api_key=config[api_source]['openai_api_key'])\n",
    "    elif api_source == 'Azure':\n",
    "        client = AzureOpenAI(api_key=config[api_source]['openai_api_key'], api_version=\"2023-12-01-preview\", azure_endpoint=config[api_source]['openai_api_endpoint'])\n",
    "    else:\n",
    "        raise Exception(f\"Unexpected API source requested: {api_source}\")\n",
    "  \n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt.format(adr, drug)\n",
    "            }\n",
    "        ],\n",
    "        model=gpt_model,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    term = chat_completion.choices[0].message.content\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = json.load(open('./config.json'))\n",
    "\n",
    "organization = \"\"\n",
    "\n",
    "api_source = 'OpenAI'\n",
    "\n",
    "api_key = config[api_source]['openai_api_key'] #constants.AZURE_OPENAI_KEY\n",
    "api_endpoint = config[api_source]['openai_api_endpoint'] \n",
    "\n",
    "gpt_model = config[api_source][\"gpt_model\"]\n",
    "temperature = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nruns = 3\n",
    "\n",
    "system_options = {\n",
    "    \"lie-detector\": \"\"\"\n",
    "    You are a lie detector. You will be given a statement and you have to determine if it is true or false.\n",
    "    Do not include an explanation. Only respond with \"true\" or \"false\".\n",
    "    \"\"\",\n",
    "    \"pharmaco-expert\": \"\"\"\n",
    "    You are a pharmacologist. You will be given a statement regarding a drug and potential adverse reaction\n",
    "    and you have to determine state whether it is true or false.\n",
    "    Do not include an explanation. Only respond with \"true\" or \"false\".\n",
    "    \"\"\",\n",
    "}\n",
    "\n",
    "prompt_options = {\n",
    "    \"side-effect\": \"\"\"\n",
    "True or False: {} is a side effect caused by {}.\n",
    "\"\"\",\n",
    "    \"adverse-reaction\": \"\"\"\n",
    "{} is an adverse reaction of {}.\n",
    "\"\"\",\n",
    "    \"caused-by\": \"\"\"\n",
    "{} is caused by {}.\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_section = pd.read_csv('/Users/undinagisladottir/Documents/Columbia/Tatonetti_Lab/20231113_onsides/adverse_reactions_active_labels.csv')\n",
    "adr_condition_name = adr_section.merge(\n",
    "    meddra_reference_map, how = 'left',\n",
    "    left_on = 'pt_meddra_id',\n",
    "    right_on = 'meddra_pt'\n",
    ")\n",
    "adr_condition_name.drop(adr_condition_name[adr_condition_name.ingredients_names.isna()].index, inplace=True)\n",
    "adr_condition_name = adr_condition_name[['condition_name', 'cohort_id', 'pt_meddra_term', 'pt_meddra_id', 'ingredients_names']]\n",
    "adr_condition_name['ingredients_names'] = adr_condition_name['ingredients_names'].str.split(',')\n",
    "adr_condition_name = adr_condition_name.explode('ingredients_names')\n",
    "adr_condition_name.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_adr_cond  = adr_condition_name.merge(\n",
    "    reference_set, left_on = ['condition_name', 'cohort_id', 'ingredients_names'], how = 'left',\n",
    "    right_on= ['condition_name', 'cohort_id', 'drug_name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_run = list()\n",
    "for _, row in ref_adr_cond.iterrows():\n",
    "    drug_name, condition_name, adr_name = row['drug_name'], row['condition_name'], row['pt_meddra_term']\n",
    "    rows_to_run.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iteration(row):\n",
    "    \n",
    "    try:\n",
    "        gpt_out = gpt_call(api_source, config, gpt_model, system_content, prompt,\n",
    "                            row['ingredients_names'], row['pt_meddra_term'], temperature)\n",
    "        return [row['ingredients_names'], row['drug_name'], row['condition_name'],\n",
    "                row['cohort_id'], row['pt_meddra_term'], row['pt_meddra_id'], row['affect'], gpt_out]\n",
    "    except Exception as err:\n",
    "        print(f\"Encountered an exception for row: {drug} {adr}. Error message below:\")\n",
    "        print(err)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{system_name}_{prompt_name}_run{i}.csv')\n",
    "for i in range(1):    \n",
    "    results = list()\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=15) as exec:\n",
    "        results.extend(list(tqdm(\n",
    "            exec.map(run_iteration, rows_to_run), \n",
    "            total=len(rows_to_run)\n",
    "        )))\n",
    "            \n",
    "    gpt_output = pd.DataFrame(\n",
    "        [r for r in results if r is not None],\n",
    "        columns=['ingredients_names', 'drug_name', 'condition_name',\n",
    "                'cohort_id', 'pt_meddra_term', 'pt_meddra_id', 'affect', 'gpt_output']\n",
    "    )\n",
    "    gpt_output.to_csv(f'{system_name}_{prompt_name}_run{i}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_cpus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
